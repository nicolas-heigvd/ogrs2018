@InProceedings{produit2018,
author="Produit, Timoth{\'e}e
and Ingensand, Jens",
editor="Mansourian, Ali
and Pilesj{\"o}, Petter
and Harrie, Lars
and van Lammeren, Ron",
title="3D Georeferencing of Historical Photos by Volunteers",
booktitle="Geospatial Technologies for All",
year="2018",
publisher="Springer International Publishing",
address="Cham",
pages="113--128",
abstract="Historical photographs are a very rich source of information that can be useful in a variety of different contexts such as environmental analyses, land planning and illustration of landscape evolution. However to reach this goal the images must be accurately georeferenced. In this paper we propose to use the crowd to perform the 3D georeferencing of collections of historical images. To this goal we implemented a web 3D georeferencer that offers volunteers the possibility to semi-automatically identify 1. the location of the point from where a picture has been taken, 2. the three angles: tilt, roll and yaw and 3. the field of view. A virtual web-based globe is the central element in this tool that allows both for the georeferencing in three dimensions by volunteers and for the visualization of georeferenced images to assess the landscape variation through time. In this paper we evaluate the method and the georeferencer and give suggestions for further developments and exploitation of the database.",
isbn="978-3-319-78208-9"
},


@inproceedings{produit2012,
  title={An open tool to register landscape oblique images and generate their synthetic model},
  author={Produit, Timothee and Tuia, Devis and Strecha, C and Golay, F},
  booktitle={Open source geospatial research and education symposium (OGRS)},
  number={EPFL-CONF-183329},
  year={2012}
},

@Article{produit2014,
AUTHOR = {Produit, T. and Tuia, D. and Lepetit, V. and Golay, F.},
TITLE = {Pose Estimation of Web-Shared Landscape Pictures},
JOURNAL = {ISPRS Annals of Photogrammetry, Remote Sensing and Spatial Information Sciences},
VOLUME = {II-3},
YEAR = {2014},
PAGES = {127--134},
URL = {https://www.isprs-ann-photogramm-remote-sens-spatial-inf-sci.net/II-3/127/2014/},
DOI = {10.5194/isprsannals-II-3-127-2014}
},



@INPROCEEDINGS{philbin2007,
author={J. Philbin and O. Chum and M. Isard and J. Sivic and A. Zisserman},
booktitle={2007 IEEE Conference on Computer Vision and Pattern Recognition},
title={Object retrieval with large vocabularies and fast spatial matching},
year={2007},
volume={},
number={},
pages={1-8},
keywords={image matching;image retrieval;quantisation (signal);object retrieval;large vocabularies;fast spatial matching;large-scale object retrieval system;query object;query image;image-feature vocabulary;scalable methods;quantization method;query performance;spatial verification stage;Web-scale image corpora;Vocabulary;Image retrieval;Quantization;Information filtering;Information filters;Silicon;Large-scale systems;Scalability;Humans;Information retrieval},
doi={10.1109/CVPR.2007.383172},
ISSN={1063-6919},
month={June},
},



@INPROCEEDINGS{hays2008,
author={J. Hays and A. A. Efros},
booktitle={2008 IEEE Conference on Computer Vision and Pattern Recognition},
title={IM2GPS: estimating geographic information from a single image},
year={2008},
volume={},
number={},
pages={1-8},
keywords={computer vision;geography;image matching;statistical distributions;IM2GPS;geographic information estimation;computer vision problem;geographically-calibrated image data;scene matching approach;GPS-tagged images;Internet;image location estimation;probability distribution;Earth surface;geolocation tasks;population density estimation;land cover estimation;urban classification;rural classification;Computer vision;Layout;Earth;Surface topography;Humans;Probability distribution;Sea surface;Global Positioning System;Planets;Internet},
doi={10.1109/CVPR.2008.4587784},
ISSN={1063-6919},
month={June},
},


@INPROCEEDINGS{feifei2005,
author={L. Fei-Fei and P. Perona},
booktitle={2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'05)},
title={A Bayesian hierarchical model for learning natural scene categories},
year={2005},
volume={2},
number={},
pages={524-531 vol. 2},
keywords={belief networks;unsupervised learning;natural scenes;image classification;image representation;Bayesian hierarchical model;learning natural scene category;training set;unsupervised learning;codeword distribution;Bayesian methods;Layout;Humans;Unsupervised learning;Animals;Vehicles;Cities and towns;Histograms;Frequency;Dictionaries},
doi={10.1109/CVPR.2005.16},
ISSN={1063-6919},
month={June},
},


@inproceedings{lazebnik2006,
  title={Beyond bags of features: Spatial pyramid matching for recognizing natural scene categories},
  author={Lazebnik, Svetlana and Schmid, Cordelia and Ponce, Jean},
  booktitle={null},
  pages={2169--2178},
  year={2006},
  organization={IEEE}
},


@InProceedings{weyand2016,
author="Weyand, Tobias
and Kostrikov, Ilya
and Philbin, James",
editor="Leibe, Bastian
and Matas, Jiri
and Sebe, Nicu
and Welling, Max",
title="PlaNet - Photo Geolocation with Convolutional Neural Networks",
booktitle="Computer Vision -- ECCV 2016",
year="2016",
publisher="Springer International Publishing",
address="Cham",
pages="37--55",
abstract="Is it possible to determine the location of a photo from just its pixels? While the general problem seems exceptionally difficult, photos often contain cues such as landmarks, weather patterns, vegetation, road markings, or architectural details, which in combination allow to infer where the photo was taken. Previously, this problem has been approached using image retrieval methods. In contrast, we pose the problem as one of classification by subdividing the surface of the earth into thousands of multi-scale geographic cells, and train a deep network using millions of geotagged images. We show that the resulting model, called PlaNet, outperforms previous approaches and even attains superhuman accuracy in some cases. Moreover, we extend our model to photo albums by combining it with a long short-term memory (LSTM) architecture. By learning to exploit temporal coherence to geolocate uncertain photos, this model achieves a 50 {\%} performance improvement over the single-image model.",
isbn="978-3-319-46484-8"
},


@Inbook{hays2015,
author="Hays, James
and Efros, Alexei A.",
editor="Choi, Jaeyoung
and Friedland, Gerald",
title="Large-Scale Image Geolocalization",
bookTitle="Multimodal Location Estimation of Videos and Images",
year="2015",
publisher="Springer International Publishing",
address="Cham",
pages="41--62",
abstract="In this chapter, we explore the task of global image geolocalization---estimating where on the Earth a photograph was captured. We examine variants of the ``im2gps'' algorithm using millions of ``geotagged'' Internet photographs as training data. We first discuss a simple to understand nearest-neighbor baseline. Next, we introduce a lazy-learning approach with more sophisticated features that doubles the performance of the original ``im2gps'' algorithm. Beyond quantifying geolocalization accuracy, we also analyze (a) how the nonuniform distribution of training data impacts the algorithm (b) how performance compares to baselines such as random guessing and land-cover recognition and (c) whether geolocalization is simply landmark or ``instance level'' recognition at a large scale. We also show that geolocation estimates can provide the basis for image understanding tasks such as population density estimation or land cover estimation. This work was originally described, in part, in ``im2gps'' [9] which was the first attempt at global geolocalization using Internet-derived training data.",
isbn="978-3-319-09861-6",
doi="10.1007/978-3-319-09861-6_3",
url="https://doi.org/10.1007/978-3-319-09861-6_3"
},


@ARTICLE{howard2017,
   author = {{Howard}, A.~G. and {Zhu}, M. and {Chen}, B. and {Kalenichenko}, D. and 
	{Wang}, W. and {Weyand}, T. and {Andreetto}, M. and {Adam}, H.
	},
    title = "{MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications}",
  journal = {ArXiv e-prints},
archivePrefix = "arXiv",
   eprint = {1704.04861},
 primaryClass = "cs.CV",
 keywords = {Computer Science - Computer Vision and Pattern Recognition},
     year = 2017,
    month = apr,
   adsurl = {http://adsabs.harvard.edu/abs/2017arXiv170404861H},
  adsnote = {Provided by the SAO/NASA Astrophysics Data System}
},


@INPROCEEDINGS{lowe1999,
author={D. G. Lowe},
booktitle={Proceedings of the Seventh IEEE International Conference on Computer Vision},
title={Object recognition from local scale-invariant features},
year={1999},
volume={2},
number={},
pages={1150-1157 vol.2},
keywords={object recognition;feature extraction;computational geometry;image matching;least squares approximations;local scale-invariant features;local image features;3D projection;inferior temporal cortex;primate vision;staged filtering approach;local geometric deformations;blurred image gradients;multiple orientation planes;nearest neighbor indexing method;candidate object matches;low residual least squares solution;unknown model parameters;robust object recognition;cluttered partially occluded images;computation time;Object recognition;Electrical capacitance tomography;Image recognition;Lighting;Neurons;Computer science;Reactive power;Filters;Programmable logic arrays;Layout},
doi={10.1109/ICCV.1999.790410},
ISSN={},
month={Sept},
},


@article{fischler1981,
 author = {Fischler, Martin A. and Bolles, Robert C.},
 title = {Random Sample Consensus: A Paradigm for Model Fitting with Applications to Image Analysis and Automated Cartography},
 journal = {Commun. ACM},
 issue_date = {June 1981},
 volume = {24},
 number = {6},
 month = jun,
 year = {1981},
 issn = {0001-0782},
 pages = {381--395},
 numpages = {15},
 url = {http://doi.acm.org/10.1145/358669.358692},
 doi = {10.1145/358669.358692},
 acmid = {358692},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {automated cartography, camera calibration, image matching, location determination, model fitting, scene analysis},
},


@inproceedings{ester1996,
  title={A density-based algorithm for discovering clusters in large spatial databases with noise.},
  author={Ester, Martin and Kriegel, Hans-Peter and Sander, J{\"o}rg and Xu, Xiaowei and others},
  booktitle={Kdd},
  volume={96},
  number={34},
  pages={226--231},
  year={1996}
},


@article{hartley1997,
  title={Triangulation},
  author={Hartley, Richard I and Sturm, Peter},
  journal={Computer vision and image understanding},
  volume={68},
  number={2},
  pages={146--157},
  year={1997},
  publisher={Academic Press}
},


@book{hartley2003,
  title={Multiple view geometry in computer vision},
  author={Hartley, Richard and Zisserman, Andrew},
  year={2003},
  publisher={Cambridge university press}
},


@book{szeliski2010,
  title={Computer vision: algorithms and applications},
  author={Szeliski, Richard},
  year={2010},
  publisher={Springer Science \& Business Media}
},




@ARTICLE{smeulders2000,
author = {M. Worring and A. W. Smeulders and A. Gupta and S. Santini and R. Jain},
journal = {IEEE Transactions on Pattern Analysis \& Machine Intelligence},
title = {Content-Based Image Retrieval at the End of the Early Years},
year = {2000},
volume = {22},
number = {},
pages = {1349-1380},
keywords={Review; content based; retrieval; semantic gap; sensory gap; narrow domain; broad domain; weak segmentation; accumulative features; salient features; signs; structural features; similarity; semantic interpretation; query space; display space; interactive session; indexing; architecture; evaluation; image databases.},
doi = {10.1109/34.895972},
url = {doi.ieeecomputersociety.org/10.1109/34.895972},
ISSN = {0162-8828},
month={12}
},


@article{veltkamp2002,
  title={Content-based image retrieval systems: A survey},
  author={Veltkamp, Remco C and Tanase, Mirela},
  journal={Department of Computing Science, Utrecht University},
  pages={1--62},
  year={2002}
},


@article{stehman1997,
title = "Selecting and interpreting measures of thematic classification accuracy",
journal = "Remote Sensing of Environment",
volume = "62",
number = "1",
pages = "77 - 89",
year = "1997",
issn = "0034-4257",
doi = "https://doi.org/10.1016/S0034-4257(97)00083-7",
url = "http://www.sciencedirect.com/science/article/pii/S0034425797000837",
author = "Stephen V. Stehman"
},




@InProceedings{baatz2012,
author="Baatz, Georges
and Saurer, Olivier
and K{\"o}ser, Kevin
and Pollefeys, Marc",
editor="Fitzgibbon, Andrew
and Lazebnik, Svetlana
and Perona, Pietro
and Sato, Yoichi
and Schmid, Cordelia",
title="Large Scale Visual Geo-Localization of Images in Mountainous Terrain",
booktitle="Computer Vision -- ECCV 2012",
year="2012",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="517--530",
abstract="Given a picture taken somewhere in the world, automatic geo-localization of that image is a task that would be extremely useful e.g. for historical and forensic sciences, documentation purposes, organization of the world's photo material and also intelligence applications. While tremendous progress has been made over the last years in visual location recognition within a single city, localization in natural environments is much more difficult, since vegetation, illumination, seasonal changes make appearance-only approaches impractical. In this work, we target mountainous terrain and use digital elevation models to extract representations for fast visual database lookup. We propose an automated approach for very large scale visual localization that can efficiently exploit visual information (contours) and geometric constraints (consistent orientation) at the same time. We validate the system on the scale of a whole country (Switzerland, 40 000km2) using a new dataset of more than 200 landscape query pictures with ground truth.",
isbn="978-3-642-33709-3"
},


@article{hartmann2016,
  title={TOWARDS COMPLETE, GEO-REFERENCED 3D MODELS FROM CROWD-SOURCED AMATEUR IMAGES.},
  author={Hartmann, Wilfried and Havlena, Michal and Schindler, Konrad},
  journal={ISPRS Annals of Photogrammetry, Remote Sensing \& Spatial Information Sciences},
  volume={3},
  number={3},
  year={2016}
},



@article{bozzini2012,
author = {C. Bozzini and M. Conedera and P. Krebs},
title ={A New Monoplotting Tool to Extract Georeferenced Vector Data and Orthorectified Raster Data from Oblique Non-Metric Photographs},
journal = {International Journal of Heritage in the Digital Era},
volume = {1},
number = {3},
pages = {499-518},
year = {2012},
doi = {10.1260/2047-4970.1.3.499},
URL = { https://doi.org/10.1260/2047-4970.1.3.499},
eprint = { https://doi.org/10.1260/2047-4970.1.3.499},
abstract = { Since its invention in the first half of the nineteenth century, photography has assumed a leading role as a means for documenting the real world. With the improvement of technology, photography developed into photogrammetry, enabling the mapping and georeferencing of landscape elements beginning with stereo photographs. With the introduction of aerial photography, terrestrial oblique photography became obsolete for cartographic purposes and was nearly forgotten by most specialists in photogrammetry. In recent times, the improvement of computing power and the production of high resolution Digital Elevation Models has made the spatial georeferincing of single oblique pictures (monoplotting) more approachable. In this paper, we focus on a new monoplotting tool developed by our research group and we illustrate the basic concept, the solutions implemented and options as well as the results of a case study on land-use and vegetation evolution over a 100-year period. The tool has been conceived to georeference ordinary individual photographs in order to orthorectify the visible landscape or to produce and export map layers (e.g. georeferenced vector data) by drawing them directly on these pictures. The basic requirements of the system are the digital version of the historical picture, the DEM of the depicted landscape, the real-world coordinates of a suitable number of control points unambiguously recognizable on the picture, and – suitable but not mandatory – the real-world coordinates of the precise shooting point and of the centre of the picture. }
},




@article{lecun2015deep,
  title={Deep learning},
  author={LeCun, Yann and Bengio, Yoshua and Hinton, Geoffrey},
  journal={nature},
  volume={521},
  number={7553},
  pages={436},
  year={2015},
  publisher={Nature Publishing Group}
},

@article{lecun1995convolutional,
  title={Convolutional networks for images, speech, and time series},
  author={LeCun, Yann and Bengio, Yoshua and others},
  journal={The handbook of brain theory and neural networks},
  volume={3361},
  number={10},
  pages={1995},
  year={1995}
},

@article{lecun1998gradient,
  title={Gradient-based learning applied to document recognition},
  author={LeCun, Yann and Bottou, L{\'e}on and Bengio, Yoshua and Haffner, Patrick},
  journal={Proceedings of the IEEE},
  volume={86},
  number={11},
  pages={2278--2324},
  year={1998},
  publisher={IEEE}
},

@article{lecun1989,
author = {LeCun, Y. and Boser, B. and Denker, J. S. and Henderson, D. and Howard, R. E. and Hubbard, W. and Jackel, L. D.},
title = {Backpropagation Applied to Handwritten Zip Code Recognition},
journal = {Neural Computation},
volume = {1},
number = {4},
pages = {541-551},
year = {1989},
doi = {10.1162/neco.1989.1.4.541},
URL = { https://doi.org/10.1162/neco.1989.1.4.541},
eprint = { https://doi.org/10.1162/neco.1989.1.4.541},
abstract = { The ability of learning networks to generalize can be greatly enhanced by providing constraints from the task domain. This paper demonstrates how such constraints can be integrated into a backpropagation network through the architecture of the network. This approach has been successfully applied to the recognition of handwritten zip code digits provided by the U.S. Postal Service. A single network learns the entire recognition operation, going from the normalized image of the character to the final classification. }
},











